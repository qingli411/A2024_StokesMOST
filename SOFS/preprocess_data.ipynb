{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface forcing at Southern Ocean Flux Station\n",
    "\n",
    "This notebook prepares input data for GOTM in a Southern Ocean Flux Station case using LES data from [Large et al., 2019](https://doi.org/10.1175/JPO-D-18-0066.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from ruamel.yaml import YAML\n",
    "sys.path.append(os.path.join(os.pardir, 'gotmtool'))\n",
    "from gotmtool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gotmtool_config = os.path.join(os.pardir, 'gotmtool', '.gotm_env.yaml')\n",
    "gotm_env = config_load(gotmtool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casename = 'AprS'\n",
    "inputdir = os.path.join(gotm_env['gotmdir_data'], 'SOFS', 'LES')\n",
    "if casename == 'AprS':\n",
    "    starttime = '2010-04-29 00:00:00'\n",
    "    stoptime   = '2010-05-01 04:30:00'\n",
    "    inputfile = 'les-april_2010.with_stokes.nc'\n",
    "elif casename == \"AprN\":\n",
    "    starttime = \"2010-04-29 00:00:00\"\n",
    "    stoptime  = \"2010-05-01 02:00:00\"\n",
    "    inputfile=\"les-april_2010.pp.no_stokes.nc\"\n",
    "elif casename== \"JunS\":\n",
    "    starttime = \"2010-06-07 06:45:00\"\n",
    "    stoptime  = \"2010-06-08 23:45:00\"\n",
    "    inputfile = \"les-june_2010.pp.with_stokes.nc\"\n",
    "elif casename == \"JunN\":\n",
    "    starttime = \"2010-06-07 06:45:00\"\n",
    "    stoptime  = \"2010-06-08 21:15:00\"\n",
    "    inputfile = \"les-june_2010.pp.no_stokes.nc\"\n",
    "else:\n",
    "    raise ValueError('Case {:s} not supported. Stop.'.format(casename))\n",
    "outputdir = 'data_{:s}'.format(casename)\n",
    "os.makedirs(outputdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File `data.yaml` contains the information of different variables for conversion. Loop over all vairables, process and save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamlfile = 'data.yaml'\n",
    "with open(yamlfile, 'r') as f:\n",
    "    fstring = f.read()\n",
    "variables = YAML().load(fstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.load_dataset(os.path.join(inputdir, inputfile))\n",
    "dttime = pd.to_datetime(starttime)+pd.to_timedelta(ds.time, unit='s')\n",
    "depth = -np.abs(ds.zu.values)*0.01 # cm -> m\n",
    "\n",
    "if '_FillValue' in ds.attrs:\n",
    "    skipvalue = ds.attrs['_FillValue']\n",
    "elif 'missing_value' in ds.attrs:\n",
    "    skipvalue = ds.attrs['missing_value']\n",
    "else:\n",
    "    skipvalue = None\n",
    "\n",
    "for var in variables:\n",
    "    branch = variables[var]\n",
    "    lname  = branch['longname']\n",
    "    print('{:s}: {:s}'.format(var, lname))\n",
    "    vtype  = branch['vartype']\n",
    "    if 'scale_factor' in branch:\n",
    "        factor = branch['scale_factor']\n",
    "    else:\n",
    "        factor = 1.    \n",
    "    oname  = os.path.join(outputdir, branch['outname'])\n",
    "    if vtype == 'scalar':\n",
    "        # scalar variable\n",
    "        vname = branch['varname']\n",
    "        data = ds.data_vars[vname].values\n",
    "        if len(data.shape) == 1:\n",
    "            dat_dump_ts(dttime, [data], oname, skip_value=skipvalue, scale_factor=factor)\n",
    "        else:\n",
    "            dat_dump_pfl(dttime, depth, [data], oname, skip_value=skipvalue, scale_factor=factor)\n",
    "    elif vtype == 'vector':\n",
    "        # vector variable\n",
    "        vnamex = branch['varnamex']\n",
    "        vnamey = branch['varnamey']\n",
    "        datax = ds.data_vars[vnamex].values\n",
    "        datay = ds.data_vars[vnamey].values\n",
    "        if len(datax.shape) == 1:\n",
    "            dat_dump_ts(dttime, [datax, datay], oname, skip_value=skipvalue, scale_factor=factor)\n",
    "        else:\n",
    "            dat_dump_pfl(dttime, depth, [datax, datay], oname, skip_value=skipvalue, scale_factor=factor)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
